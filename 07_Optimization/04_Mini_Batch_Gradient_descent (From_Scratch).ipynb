{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0ee50f9-e858-4a55-87a1-ff96ba74d5fe",
   "metadata": {},
   "source": [
    "# Mini-Batch Gradient Descent\n",
    "\n",
    "`Mini-Batch Gradient Descent` is a variant of gradient descent that updates model parameters using\n",
    "**small batches of training samples** instead of the entire dataset or a single sample.\n",
    "\n",
    "It provides the **best trade-off between speed and stability** and is the most widely used optimization\n",
    "method in modern machine learning and deep learning.\n",
    "\n",
    "---\n",
    "\n",
    "## How Mini-Batch Gradient Descent Works\n",
    "\n",
    "At each iteration:\n",
    "1. Shuffle the training dataset  \n",
    "2. Split data into small batches (mini-batches)  \n",
    "3. Compute gradients using one mini-batch  \n",
    "4. Update model parameters  \n",
    "5. Repeat for all mini-batches (one epoch)\n",
    "\n",
    "---\n",
    "\n",
    "## Update Rule\n",
    "\n",
    "For a mini-batch of size \\( b \\):\n",
    "\n",
    "$$\n",
    "\\theta := \\theta - \\alpha \\frac{1}{b}\n",
    "\\sum_{i=1}^{b} \\nabla_\\theta L(\\hat{y}^{(i)}, y^{(i)})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $(\\theta)$ = model parameters  \n",
    "- $(\\alpha)$ = learning rate  \n",
    "- $(b)$ = mini-batch size  \n",
    "\n",
    "---\n",
    "\n",
    "## Choosing the Batch Size\n",
    "\n",
    "Common mini-batch sizes:\n",
    "- 16, 32, 64, 128  \n",
    "\n",
    "Batch size affects:\n",
    "- Training speed  \n",
    "- Memory usage  \n",
    "- Convergence stability  \n",
    "\n",
    "Smaller batches → noisier updates  \n",
    "Larger batches → smoother but slower updates  \n",
    "\n",
    "---\n",
    "\n",
    "## Characteristics\n",
    "\n",
    "- Multiple updates per epoch  \n",
    "- Balanced gradient estimation  \n",
    "- Efficient use of hardware (CPU/GPU)  \n",
    "- Smooth but fast convergence  \n",
    "\n",
    "---\n",
    "\n",
    "## Advantages\n",
    "\n",
    "- Faster than Batch Gradient Descent  \n",
    "- More stable than SGD  \n",
    "- Scales well to large datasets  \n",
    "- Suitable for parallel computation  \n",
    "\n",
    "---\n",
    "\n",
    "## Limitations\n",
    "\n",
    "- Requires tuning batch size  \n",
    "- Still sensitive to learning rate  \n",
    "- Can get stuck in local minima for non-convex problems  \n",
    "\n",
    "---\n",
    "\n",
    "## When to Use Mini-Batch Gradient Descent\n",
    "\n",
    "Mini-Batch Gradient Descent is ideal when:\n",
    "- Dataset is large  \n",
    "- GPU or parallel hardware is available  \n",
    "- Stability and speed are both important  \n",
    "- Training deep learning models  \n",
    "\n",
    "---\n",
    "\n",
    "## Comparison with Other Variants\n",
    "\n",
    "| Method | Data Used per Update | Speed | Stability |\n",
    "|------|---------------------|-------|-----------|\n",
    "| Batch GD | Entire dataset | Slow | Very High |\n",
    "| SGD | Single sample | Very Fast | Low |\n",
    "| Mini-Batch GD | Small batch | Fast | Medium–High |\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "Mini-Batch Gradient Descent combines the strengths of Batch Gradient Descent and Stochastic Gradient Descent.\n",
    "By using small batches of data, it achieves fast training, stable convergence, and efficient hardware utilization,\n",
    "making it the default choice for most machine learning and deep learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a272399-f813-4d7f-b8da-1b62786f7f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b751a602-78c4-488e-b1aa-e47e7837bd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "060308e7-3ce8-4bec-80d8-46b3787d1c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "X,y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b80d8685-893a-4f74-91f3-08384baafb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n",
      "(442,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb07b91-d940-400c-846f-e4ae5a8539f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c6770c-8702-4457-8bb3-e12e7b5668cf",
   "metadata": {},
   "source": [
    "### Creating Own Mini Batch Gradient Descent Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e10aff2-b5c2-4fc4-b336-6298418d0256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class MBGDRegressor:\n",
    "    \n",
    "    def __init__(self,batch_size,learning_rate=0.01,epochs=100):\n",
    "        \n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def fit(self,X_train,y_train):\n",
    "        # init your coefs\n",
    "        self.intercept_ = 0\n",
    "        self.coef_ = np.ones(X_train.shape[1])\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            for j in range(int(X_train.shape[0]/self.batch_size)):\n",
    "                \n",
    "                idx = random.sample(range(X_train.shape[0]),self.batch_size)\n",
    "                \n",
    "                y_hat = np.dot(X_train[idx],self.coef_) + self.intercept_\n",
    "                #print(\"Shape of y_hat\",y_hat.shape)\n",
    "                intercept_der = -2 * np.mean(y_train[idx] - y_hat)\n",
    "                self.intercept_ = self.intercept_ - (self.lr * intercept_der)\n",
    "\n",
    "                coef_der = -2 * np.dot((y_train[idx] - y_hat),X_train[idx])\n",
    "                self.coef_ = self.coef_ - (self.lr * coef_der)\n",
    "        \n",
    "        print(self.intercept_,self.coef_)\n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        return np.dot(X_test,self.coef_) + self.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf3b83df-fd5c-445f-9b24-111e495a11d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbr = MBGDRegressor(batch_size=int(X_train.shape[0]/50),learning_rate=0.01,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f21bf92-5902-4c62-8a16-d60deea99ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152.73914716353028 [  25.48513263 -132.09677548  454.7927651   304.54619762  -17.54755095\n",
      "  -87.02674564 -186.48037159  112.92870132  411.52692739  111.79906255]\n"
     ]
    }
   ],
   "source": [
    "mbr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c37f3e9b-f955-4e55-abc5-073f303b5ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13a32f18-b824-4c77-a11b-205a14cb17e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4515814462813902"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6d1050-a0b9-4e37-a649-bf66c94246b2",
   "metadata": {},
   "source": [
    "### Using Scikit-Learn Built-in Gradient Descent Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de985936-1511-4806-8373-07397afc5ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b516c18-5f3f-4a83-90ea-809df9343e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDRegressor(learning_rate='constant',eta0=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "990246ea-c461-452d-b92a-9045271d50d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 35\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    idx = random.sample(range(X_train.shape[0]),batch_size)\n",
    "    sgd.partial_fit(X_train[idx],y_train[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2d97764-ce36-4261-90fc-e6b307ec0ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  58.38755699,  -70.86857683,  356.55716034,  259.91093245,\n",
       "         11.81546429,  -33.17869112, -179.77522828,  134.87474357,\n",
       "        324.52423427,  134.09083859])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26057d2b-f1c3-4cc1-b17e-4be646ebfb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([150.43560229])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "baccf3f9-9fa7-483c-a4e4-9f33a7deaa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sgd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed4b6b66-1849-439c-b7cb-cc83991f13e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4351399142157185"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
