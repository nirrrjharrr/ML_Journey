{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ad6d081-8bf0-42cf-b472-881b73b28797",
   "metadata": {},
   "source": [
    "# Batch Gradient Descent\n",
    "\n",
    "`Batch Gradient Descent` is a variant of gradient descent where the **entire training dataset**\n",
    "is used to compute the gradient of the loss function **at each update step**.\n",
    "\n",
    "It provides stable and smooth convergence but can be computationally expensive for large datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## How Batch Gradient Descent Works\n",
    "\n",
    "At each iteration:\n",
    "1. Use **all training samples** to compute the gradient  \n",
    "2. Update model parameters once per iteration  \n",
    "3. Repeat until the cost function converges  \n",
    "\n",
    "Only **one update** is performed per epoch.\n",
    "\n",
    "---\n",
    "\n",
    "## Update Rule\n",
    "\n",
    "For a cost function \\( J(\\theta) \\), the update rule is:\n",
    "\n",
    "$$\n",
    "\\theta := \\theta - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} \\nabla_\\theta L(\\hat{y}^{(i)}, y^{(i)})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $(m)$ = number of training samples  \n",
    "- $(\\alpha)$ = learning rate  \n",
    "- $\\nabla_\\theta L$ = gradient of the loss function  \n",
    "\n",
    "---\n",
    "\n",
    "## Example: Linear Regression\n",
    "\n",
    "For Mean Squared Error (MSE):\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)})^2\n",
    "$$\n",
    "\n",
    "The gradient is computed using **all samples** before updating parameters.\n",
    "\n",
    "---\n",
    "\n",
    "## Characteristics\n",
    "\n",
    "- Deterministic updates  \n",
    "- Smooth and stable convergence  \n",
    "- Exact gradient at each step  \n",
    "- One update per epoch  \n",
    "\n",
    "---\n",
    "\n",
    "## Advantages\n",
    "\n",
    "- Guaranteed convergence for convex loss functions  \n",
    "- Stable and predictable updates  \n",
    "- Easier to debug and analyze  \n",
    "\n",
    "---\n",
    "\n",
    "## Limitations\n",
    "\n",
    "- Slow for large datasets  \n",
    "- High memory usage  \n",
    "- Not suitable for online learning  \n",
    "- Can be inefficient when data is large  \n",
    "\n",
    "---\n",
    "\n",
    "## When to Use Batch Gradient Descent\n",
    "\n",
    "Batch Gradient Descent is suitable when:\n",
    "- Dataset size is small to medium  \n",
    "- High precision in gradient computation is required  \n",
    "- The loss function is convex  \n",
    "- Training time is not a major concern  \n",
    "\n",
    "---\n",
    "\n",
    "## Batch Gradient Descent vs Other Variants\n",
    "\n",
    "| Method | Data Used per Update | Speed | Stability |\n",
    "|------|---------------------|-------|-----------|\n",
    "| Batch GD | Entire dataset | Slow | Very High |\n",
    "| SGD | Single sample | Fast | Low |\n",
    "| Mini-Batch GD | Small batch | Balanced | Medium |\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "Batch Gradient Descent computes parameter updates using the entire dataset at each iteration.\n",
    "While it offers stable and accurate convergence, it is computationally expensive and less suitable\n",
    "for large-scale machine learning problems compared to mini-batch methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8524a46-fa33-4103-b7fd-c55338b4f0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f02f5027-079c-4cbb-94ca-72fa89e9f779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3773d18d-2021-4d7b-bc15-da9215d087e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "777b4ccc-1fb3-4638-867c-9eb080e42ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "818cd0d8-bfad-4d9d-a4ca-dbdc9cc092d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb9d0f49-4819-43dd-a5fa-9efc325776b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n",
      "(442,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e08b9547-0530-4cb1-b09e-b6a65da2d1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d2efc37-c0e6-4754-bc9a-9de3944aca4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(353, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a0c3f9-ed6f-44c0-9d3a-3c43e7588cc4",
   "metadata": {},
   "source": [
    "### Creating Own Batch Gradient Descent Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d39be027-4004-44dc-9614-8a4833a022ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDRegressor:\n",
    "    \n",
    "    def __init__(self,learning_rate=0.01,epochs=100):\n",
    "        \n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def fit(self,X_train,y_train):\n",
    "        # init your coefs\n",
    "        self.intercept_ = 0\n",
    "        self.coef_ = np.ones(X_train.shape[1])\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            # update all the coef and the intercept\n",
    "            y_hat = np.dot(X_train,self.coef_) + self.intercept_\n",
    "            #print(\"Shape of y_hat\",y_hat.shape)\n",
    "            intercept_der = -2 * np.mean(y_train - y_hat)\n",
    "            self.intercept_ = self.intercept_ - (self.lr * intercept_der)\n",
    "            \n",
    "            coef_der = -2 * np.dot((y_train - y_hat),X_train)/X_train.shape[0]\n",
    "            self.coef_ = self.coef_ - (self.lr * coef_der)\n",
    "        \n",
    "        print(self.intercept_,self.coef_)\n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        return np.dot(X_test,self.coef_) + self.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5aea553-50e9-4a14-b94b-9ab5d558e68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdr = GDRegressor(epochs=1000,learning_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae7b00c8-3396-40f1-ac52-91ce6b202fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152.01351687661833 [  14.38990585 -173.7235727   491.54898524  323.91524824  -39.32648042\n",
      " -116.01061213 -194.04077415  103.38135565  451.63448787   97.57218278]\n"
     ]
    }
   ],
   "source": [
    "gdr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "861a950b-0a6b-470c-afbf-e0a858a637d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gdr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a3334ea-69ec-4033-8f4f-d457a6715e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4534503034722803"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a5c51d-a62d-402f-9a7c-4384ceb60842",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
